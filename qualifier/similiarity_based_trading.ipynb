{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# External libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "submission_raw = pd.read_csv(\"./data/raw_data/past_open/sample_submission.csv\")\n",
    "\n",
    "datasets_df_raw_v1 = pd.read_csv(\"./data/raw_data/past_open/train.csv\")\n",
    "datasets_df_raw_v2 = pd.read_csv(\"./data/raw_data/train_additional.csv\")\n",
    "\n",
    "column_dict = {\n",
    "    \"일자\": \"date\",\n",
    "    \"종목코드\": \"ticker_code\",\n",
    "    \"종목명\": \"ticker_name\",\n",
    "    \"거래량\": \"volume\",\n",
    "    \"시가\": \"open\",\n",
    "    \"고가\": \"high\",\n",
    "    \"저가\": \"low\",\n",
    "    \"종가\": \"close\",\n",
    "}\n",
    "\n",
    "datasets_df_raw = pd.concat([datasets_df_raw_v1, datasets_df_raw_v2], axis=0)\n",
    "\n",
    "datasets_df = datasets_df_raw.copy()\n",
    "submission_df = submission_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General preprocessing\n",
    "# 1. Column name mapping\n",
    "def map_column_names(datasets_df, column_dict):\n",
    "    datasets_df.columns = [column_dict[column] for column in datasets_df.columns]\n",
    "    return datasets_df\n",
    "\n",
    "\n",
    "# 2. Drop outliers\n",
    "def drop_zero(datasets_df):\n",
    "    columns = [\"volume\", \"open\", \"low\", \"high\", \"close\"]\n",
    "    for column in columns:\n",
    "        datasets_df = datasets_df[datasets_df[column] != 0]\n",
    "    return datasets_df\n",
    "\n",
    "\n",
    "# 3. Drop lack data\n",
    "class DROP_LACK_DATA:\n",
    "    def __init__(self, df, percentage) -> None:\n",
    "        self.df = df\n",
    "        self.percentage = percentage\n",
    "\n",
    "    def get_ticker_count_series(self):\n",
    "        df = self.df\n",
    "        ticker_count_series = df.groupby(\"ticker_code\").count()[\"date\"]\n",
    "        return ticker_count_series\n",
    "\n",
    "    def get_available_tickers(self, ticker_count_series):\n",
    "        percentage = self.percentage\n",
    "\n",
    "        available_tickers = ticker_count_series[\n",
    "            ticker_count_series > ticker_count_series.max() * percentage\n",
    "        ].index\n",
    "        return available_tickers\n",
    "\n",
    "    def filter_available_tickers(self, available_tickers):\n",
    "        df = self.df\n",
    "        df = df[df[\"ticker_code\"].isin(available_tickers)]\n",
    "        return df\n",
    "\n",
    "    def __call__(self):\n",
    "        ticker_count_series = self.get_ticker_count_series()\n",
    "        available_tickers = self.get_available_tickers(ticker_count_series)\n",
    "        df = self.filter_available_tickers(available_tickers)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "\n",
    "# 1. Get tickers\n",
    "def get_ticker_codes(datasets_df):\n",
    "    ticker_codes = sorted(set(datasets_df[\"ticker_code\"]))\n",
    "    return ticker_codes\n",
    "\n",
    "# 2. Sort data by date\n",
    "def sort_dataset_df(dataset_df, column):\n",
    "    sorted_dataset_df = dataset_df.sort_values(column)\n",
    "    return sorted_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model preprocessing\n",
    "# 1. Append price diff\n",
    "def append_price_diff(dataset, open_col, close_col):\n",
    "    dataset[\"price_diff\"] = (dataset[open_col] - dataset[close_col]) / dataset[open_col]\n",
    "    return dataset\n",
    "\n",
    "# 2. Get arraylist\n",
    "def get_array_list(dataset, column):\n",
    "    _arraylist = dataset[column].values\n",
    "    return _arraylist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model format dataset\n",
    "\n",
    "def get_x_y_dataset(arraylist, CFG):\n",
    "    i_window = CFG[\"input_window\"]\n",
    "    o_window = CFG[\"output_window\"]\n",
    "\n",
    "    x_dataset = list()\n",
    "    y_dataset = list()\n",
    "\n",
    "    for idx in range(len(arraylist) - i_window - o_window + 1):\n",
    "        _x = arraylist[idx : idx + i_window]\n",
    "        _y = arraylist[idx + i_window : idx + i_window + o_window]\n",
    "        x_dataset.append(_x)\n",
    "        y_dataset.append(_y)\n",
    "\n",
    "    x_dataset = np.array(x_dataset)\n",
    "    y_dataset = np.array(y_dataset)\n",
    "    return x_dataset, y_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "## Get similairty_score\n",
    "def get_cosine_similarity(array_1, array_2):\n",
    "    cosine_similarity = np.dot(array_1, array_2) / (\n",
    "        np.linalg.norm(array_1) * np.linalg.norm(array_2)\n",
    "    )\n",
    "    return cosine_similarity\n",
    "\n",
    "\n",
    "def get_similarity_df(x_dataset, y_dataset, final_x):\n",
    "    similarity_results = list()\n",
    "    for x_data, y_data in zip(x_dataset, y_dataset):\n",
    "        _similarity_score = get_cosine_similarity(x_data, final_x)\n",
    "        similarity_results.append(\n",
    "            {\n",
    "                \"similarity_score\": _similarity_score,\n",
    "                \"actual_y\": y_data,\n",
    "            }\n",
    "        )\n",
    "    similarity_df = pd.DataFrame(similarity_results)\n",
    "    return similarity_df\n",
    "\n",
    "\n",
    "def get_similarity_main_df(x_dataset, y_dataset, final_x, n):\n",
    "    similarity_results = list()\n",
    "    for x_data, y_data in zip(x_dataset, y_dataset):\n",
    "        _similarity_score = get_cosine_similarity(x_data, final_x)\n",
    "        similarity_results.append(\n",
    "            {\n",
    "                \"similarity_score\": _similarity_score,\n",
    "                \"actual_y\": y_data,\n",
    "            }\n",
    "        )\n",
    "    similarity_df = pd.DataFrame(similarity_results)\n",
    "    similarity_main_df = similarity_df.nlargest(n, \"similarity_score\")\n",
    "    return similarity_main_df\n",
    "\n",
    "\n",
    "def get_pred_y(similarity_df):\n",
    "    pred_y = (similarity_df[\"similarity_score\"] * similarity_df[\"actual_y\"]).mean()\n",
    "    return pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    \"dataset_window\": 300,\n",
    "    \"input_window\": 20,\n",
    "    \"output_window\": 15,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "General Preprocessing \n",
    "\"\"\"\n",
    "datasets_df = map_column_names(datasets_df, column_dict)\n",
    "datasets_df = drop_zero(datasets_df)\n",
    "datasets_df = DROP_LACK_DATA(datasets_df, 0.8)()\n",
    "\n",
    "\"\"\"\n",
    "Main\n",
    "\"\"\"\n",
    "ticker_codes = get_ticker_codes(datasets_df)\n",
    "\n",
    "ticker_pred_dict = dict()\n",
    "for ticker_code in tqdm(ticker_codes):\n",
    "    dataset_df = datasets_df[datasets_df[\"ticker_code\"] == ticker_code]\n",
    "\n",
    "    \"\"\" \n",
    "    Utils\n",
    "    \"\"\"\n",
    "    dataset_df = sort_dataset_df(dataset_df, \"date\")\n",
    "    dataset_df = append_price_diff(dataset_df, \"open\", \"close\")\n",
    "\n",
    "    \"\"\"\n",
    "    Model Preprocessing\n",
    "    \"\"\"\n",
    "    price_diff_arraylist = get_array_list(dataset_df, \"price_diff\")\n",
    "    price_diff_arraylist = price_diff_arraylist[\n",
    "        -(CFG[\"dataset_window\"] + CFG[\"input_window\"]) :\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "    Model format Dataset\n",
    "    \"\"\"\n",
    "    x_dataset, y_dataset = get_x_y_dataset(price_diff_arraylist, CFG)\n",
    "    y_dataset = y_dataset.sum(axis=1)\n",
    "    final_x = price_diff_arraylist[-CFG[\"input_window\"] :]\n",
    "    \"\"\"\n",
    "    Model\n",
    "    \"\"\"\n",
    "    similarity_main_df = get_similarity_main_df(x_dataset, y_dataset, final_x, 3)\n",
    "    pred_y = get_pred_y(similarity_main_df)\n",
    "\n",
    "    ticker_pred_dict[ticker_code] = pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission_df(submission, ticker_score_dict):\n",
    "    submission[\"score\"] = submission[\"종목코드\"].map(ticker_score_dict)\n",
    "    submission[\"score\"] = submission[\"score\"].fillna(0)\n",
    "    submission[\"순위\"] = (\n",
    "        submission[\"score\"].rank(method=\"first\", ascending=False).astype(int)\n",
    "    )\n",
    "    submission_result = submission.loc[:, [\"종목코드\", \"순위\"]]\n",
    "    return submission_result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = submission_raw.copy()\n",
    "submission_result = make_submission_df(submission, ticker_pred_dict)\n",
    "\n",
    "submission_result.to_csv(\n",
    "    f\"./data/final_result/final_similarity_{CFG['dataset_window']}_{CFG['input_window']}_{CFG['output_window']}.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
